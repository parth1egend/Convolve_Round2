{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve Epoch 2\n",
    "## Round 2\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing training and final testing data \n",
    "\n",
    "train_data_filename = \"/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/dataset/Dev_data_to_be_shared.xlsx\"\n",
    "test_data_filename = \"/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/dataset/validation_data_to_be_shared.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `Excel` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(train_data_filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df.csv\",  \n",
    "                  index = None, \n",
    "                  header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(test_data_filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_df.csv\",  \n",
    "                  index = None, \n",
    "                  header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `.info()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>account_opening_date</th>\n",
       "      <th>demog_1</th>\n",
       "      <th>demog_3</th>\n",
       "      <th>demog_5</th>\n",
       "      <th>demog_6</th>\n",
       "      <th>demog_7</th>\n",
       "      <th>demog_8</th>\n",
       "      <th>demog_9</th>\n",
       "      <th>...</th>\n",
       "      <th>others_41</th>\n",
       "      <th>txn_80</th>\n",
       "      <th>txn_81</th>\n",
       "      <th>demog_39</th>\n",
       "      <th>demog_41</th>\n",
       "      <th>others_42</th>\n",
       "      <th>others_43</th>\n",
       "      <th>others_44</th>\n",
       "      <th>others_45</th>\n",
       "      <th>demog_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>96331.000000</td>\n",
       "      <td>99994.000000</td>\n",
       "      <td>99975.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99994.0</td>\n",
       "      <td>96249.000000</td>\n",
       "      <td>87086.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>42522.000000</td>\n",
       "      <td>48535.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>2105.000000</td>\n",
       "      <td>4579.000000</td>\n",
       "      <td>874.000000</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2023-01-25 16:25:19.200000512</td>\n",
       "      <td>79.543376</td>\n",
       "      <td>101.323279</td>\n",
       "      <td>3.290163</td>\n",
       "      <td>1.017180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.191701</td>\n",
       "      <td>0.326103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>34.742439</td>\n",
       "      <td>22.679159</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.96329</td>\n",
       "      <td>87.887886</td>\n",
       "      <td>62.024896</td>\n",
       "      <td>28.808924</td>\n",
       "      <td>96.700288</td>\n",
       "      <td>0.958470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-01 00:00:00</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-01-25 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-02-24 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13907.000000</td>\n",
       "      <td>7810.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>3283.000000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>0.140001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.498781</td>\n",
       "      <td>5.350011</td>\n",
       "      <td>0.833449</td>\n",
       "      <td>0.182553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641951</td>\n",
       "      <td>0.468788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>251.845838</td>\n",
       "      <td>49.903348</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.18805</td>\n",
       "      <td>298.951251</td>\n",
       "      <td>200.384998</td>\n",
       "      <td>136.963658</td>\n",
       "      <td>370.396893</td>\n",
       "      <td>0.199514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Primary key         Target           account_opening_date  \\\n",
       "count  100000.000000  100000.000000                         100000   \n",
       "mean    50000.500000       0.020000  2023-01-25 16:25:19.200000512   \n",
       "min         1.000000       0.000000            2022-12-01 00:00:00   \n",
       "25%     25000.750000       0.000000            2022-12-26 00:00:00   \n",
       "50%     50000.500000       0.000000            2023-01-25 00:00:00   \n",
       "75%     75000.250000       0.000000            2023-02-24 00:00:00   \n",
       "max    100000.000000       1.000000            2023-03-31 00:00:00   \n",
       "std     28867.657797       0.140001                            NaN   \n",
       "\n",
       "            demog_1       demog_3       demog_5       demog_6  demog_7  \\\n",
       "count  96331.000000  99994.000000  99975.000000  99999.000000  99994.0   \n",
       "mean      79.543376    101.323279      3.290163      1.017180      1.0   \n",
       "min       51.000000    101.000000      1.000000      1.000000      1.0   \n",
       "25%       55.000000    101.000000      3.000000      1.000000      1.0   \n",
       "50%       55.000000    101.000000      4.000000      1.000000      1.0   \n",
       "75%       55.000000    101.000000      4.000000      1.000000      1.0   \n",
       "max      421.000000    213.000000      4.000000      4.000000      1.0   \n",
       "std       89.498781      5.350011      0.833449      0.182553      0.0   \n",
       "\n",
       "            demog_8       demog_9  ...     others_41        txn_80  \\\n",
       "count  96249.000000  87086.000000  ...  99999.000000  42522.000000   \n",
       "mean      41.191701      0.326103  ...      0.002220     34.742439   \n",
       "min       41.000000      0.000000  ...      0.000000      1.000000   \n",
       "25%       41.000000      0.000000  ...      0.000000      2.000000   \n",
       "50%       41.000000      0.000000  ...      0.000000      5.000000   \n",
       "75%       41.000000      1.000000  ...      0.000000     15.000000   \n",
       "max       52.000000      1.000000  ...      1.000000  13907.000000   \n",
       "std        0.641951      0.468788  ...      0.047065    251.845838   \n",
       "\n",
       "             txn_81       demog_39      demog_41    others_42    others_43  \\\n",
       "count  48535.000000  100000.000000  100000.00000  2105.000000  4579.000000   \n",
       "mean      22.679159       0.999940       0.96329    87.887886    62.024896   \n",
       "min        1.000000       0.000000       0.00000     0.000000     0.000000   \n",
       "25%        6.000000       1.000000       1.00000     0.000000     0.000000   \n",
       "50%       12.000000       1.000000       1.00000     0.000000     0.000000   \n",
       "75%       27.000000       1.000000       1.00000     2.000000     4.000000   \n",
       "max     7810.000000       1.000000       1.00000  4049.000000  3283.000000   \n",
       "std       49.903348       0.007746       0.18805   298.951251   200.384998   \n",
       "\n",
       "         others_44    others_45       demog_42  \n",
       "count   874.000000   694.000000  100000.000000  \n",
       "mean     28.808924    96.700288       0.958470  \n",
       "min       0.000000     0.000000       0.000000  \n",
       "25%       0.000000     0.000000       1.000000  \n",
       "50%       0.000000     0.000000       1.000000  \n",
       "75%       0.000000     0.000000       1.000000  \n",
       "max    2922.000000  3603.000000       1.000000  \n",
       "std     136.963658   370.396893       0.199514  \n",
       "\n",
       "[8 rows x 166 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key                      int64\n",
       "Target                           int64\n",
       "account_opening_date    datetime64[ns]\n",
       "country_code                    object\n",
       "demog_1                        float64\n",
       "                             ...      \n",
       "others_43                      float64\n",
       "others_44                      float64\n",
       "others_45                      float64\n",
       "demog_42                         int64\n",
       "demog_43                        object\n",
       "Length: 178, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key             100000\n",
       "Target                       2\n",
       "account_opening_date       121\n",
       "country_code                49\n",
       "demog_1                     16\n",
       "                         ...  \n",
       "others_43                  479\n",
       "others_44                   99\n",
       "others_45                  135\n",
       "demog_42                     2\n",
       "demog_43                     3\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key                 0\n",
       "Target                      0\n",
       "account_opening_date        0\n",
       "country_code             3666\n",
       "demog_1                  3669\n",
       "                        ...  \n",
       "others_43               95421\n",
       "others_44               99126\n",
       "others_45               99306\n",
       "demog_42                    0\n",
       "demog_43                 3705\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing the `columns` of the `train_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary key', 'Target', 'account_opening_date', 'country_code',\n",
       "       'demog_1', 'demog_2', 'income', 'demog_3', 'city_tier', 'occupation',\n",
       "       ...\n",
       "       'demog_39', 'email_domain', 'demog_40', 'demog_41', 'others_42',\n",
       "       'others_43', 'others_44', 'others_45', 'demog_42', 'demog_43'],\n",
       "      dtype='object', length=178)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the `cols` against `Target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exclude 'Primary key' column and split into batches of 40 columns each\n",
    "columns_to_plot = [col for col in train_df.columns if col != 'Primary key']\n",
    "batch_size = 40\n",
    "\n",
    "# Create a directory to save the images (change the path as needed)\n",
    "image_directory = '/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/image_directory/'\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "\n",
    "# Create plots for the first batch of attributes against 'Target' and save as images\n",
    "for i in range(0, min(batch_size, len(columns_to_plot))):\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    \n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the second batch of attributes against 'Target'\n",
    "for i in range(batch_size, 2 * batch_size):\n",
    "    if i >= len(columns_to_plot):\n",
    "        break\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the third batch of attributes against 'Target'\n",
    "for i in range(2 * batch_size, 3 * batch_size):\n",
    "    if i >= len(columns_to_plot):\n",
    "        break\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    \n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the fourth batch of attributes against 'Target'\n",
    "for i in range(3 * batch_size, len(columns_to_plot)):\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The images are saved in a file as they are heavy files and slowing down the notebook.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we infer from the graphs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `txn_61`\n",
    "  - 1871 points have target 1\n",
    "  - Value 0 -> Always\n",
    "- `txn_62`\n",
    "  - Value 0 -> 1866 have target 1\n",
    "  - Value 1 -> 696 have target 0, very few have target 1\n",
    "- `txn_63`\n",
    "  - Value 0 -> 1867 have target 1\n",
    "  - At other datapoints very less values of both targets\n",
    "- `txn_64`\n",
    "  - Value 0 -> Many mules , target value 1\n",
    "  - Mules happen at single digit values, but it takes values till 200.\n",
    "- `txn_65`\n",
    "  - Value -> Always 0\n",
    "  - 1871 have target 1\n",
    "- `txn_66`\n",
    "  - 1800s have target 1\n",
    "  - Value 0 -> Always\n",
    "- `txn_67`\n",
    "  - Target 1 at Values 0 like before\n",
    "- `txn_68`\n",
    "  - Wide range of values from 0 - 17000\n",
    "  - Value 0 -> 1800s mules\n",
    "  - Few mules , max till value till 700.\n",
    "- `txn_69`\n",
    "  - Value 0 -> 1200s\n",
    "  - Value 1 -> 500s\n",
    "  - Value 2 -> 150s\n",
    "  - Value 3 -> 70s\n",
    "  - Mules till 15.\n",
    "- `txn_70`\n",
    "  - Value only 0, 1800s target 1\n",
    "- `txn_73`\n",
    "  - Different & Visible pattern\n",
    "  - Decreasing graph\n",
    "- `txn_74`\n",
    "  - Different pattern\n",
    "  - Like txn_73\n",
    "- `txn_75`\n",
    "  - Different pattern like txn_74\n",
    "- `txn_76`\n",
    "  - Different and like txn_75\n",
    "- `txn_77`\n",
    "  - Slightly higher peak at zero, like txn_76\n",
    "  - Different pattern, slight right skewness\n",
    "- `txn_78`\n",
    "  - Like `txn_77`\n",
    "- `txn_79`\n",
    "  - Like txn_78\n",
    "\n",
    "`txn_73` :- `txn_80` ,`txn_81`(Peak spikes), \n",
    "  \n",
    "\n",
    "- `others_1`\n",
    "  - Value 0 -> 1700s Mules\n",
    "  - Value 1 -> 200s Mules\n",
    "- `others_3`\n",
    "  - Proportion of mules at Value 1 more\n",
    "- `others_6`\n",
    "  - Different pattern\n",
    "  - Number of Mules at lower values are higher in comparison to later values.\n",
    "- `others_7`\n",
    "  - Same like other_6, looks important.\n",
    "- `others_8`\n",
    "  - Mules at lower values only.\n",
    "- `others_9`\n",
    "  - Looks important, like others_6.\n",
    "- `others_10`\n",
    "  - Looks like others_6\n",
    "- `others_12`\n",
    "  - Looks like others_6\n",
    "- `others_11`\n",
    "  - Like others_8\n",
    "\n",
    "`others_6` :- `others_13` ,`others_15` , `others_16`  \n",
    "`others_8` :- `others_14` , `others_17` , `others_18` , `others_19`, `others_20` ,`others_21` ,`others_22` ,`others_24`, `others_25` ,`others_23` , `others_26` ,`others_29`,`others_30`,`others_31`,`others_32`,`others_37`\n",
    "\n",
    "\n",
    "\n",
    "- `others_36`\n",
    "  - Different pattern, mules at higher values.\n",
    "\n",
    "\n",
    "`email_domain` :No pattern as such\n",
    "\n",
    "`demog_40` , `demog_43`: Categorical , interesting, column . High value imples more mules.\n",
    "`others_42` : Mules at lower values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Target`\n",
    "Only 2% of our targets are 1, such low number of mules banks makes sense\n",
    "\n",
    "- `Dates`\n",
    "Dates have been given last 4 months of financial year 2022-23. There is slight rise in mules in later part of January\n",
    "\n",
    "- `Country Code`\n",
    "Most of the people are from India(above 90%) and all mules are Indians\n",
    "\n",
    "- `Demog_2`\n",
    "There is a significant rise in Mule values around 2 and 3 \n",
    "\n",
    "- `Income`\n",
    "There is a trend of more mules with lower income values.\n",
    "\n",
    "- `City-Tier`\n",
    "Higher number of mules from Rural area, and significantly less from Tier-1\n",
    "\n",
    "- `Occupation`\n",
    "Saliered and Student have very low percentage of mules, Self-Employed have significantly high number of mules.\n",
    "\n",
    "- `Demog_4`\n",
    "Most frauders have N value but 90% of values are itself N.\n",
    "\n",
    "- `Demog_9`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Deomog_13`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Deomog_14`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Demog_20`\n",
    "Significant drop from 0.5 to 1.5\n",
    "\n",
    "- `Demog_21`\n",
    "Significant drop from 0.5 to 1.5\n",
    "\n",
    "- `Demog_22`\n",
    "All mules in Y, but very low number of N in total\n",
    "\n",
    "- `os`\n",
    "Significant mules in Android, only 0.8% of IoS are mules\n",
    "\n",
    "- `tx_1-15`\n",
    "Most values are 0 itself(distribution is also very similar expect very few outliers)\n",
    "\n",
    "- `tx_53`\n",
    "Still mules around 0 and 1 values but different from general pattern, mules are more on 0 than 1.\n",
    "\n",
    "- `tx_54`\n",
    "High number of values at 2 but very low mules.\n",
    "\n",
    "- `demog_23` , `demog_32`\n",
    "Lower values have higher mules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
