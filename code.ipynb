{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve Epoch 2\n",
    "## Round 2\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing training and final testing data \n",
    "\n",
    "train_data_filename = \"/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/dataset/Dev_data_to_be_shared.xlsx\"\n",
    "test_data_filename = \"/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/dataset/validation_data_to_be_shared.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `Excel` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(train_data_filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df.csv\",  \n",
    "                  index = None, \n",
    "                  header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(test_data_filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_df.csv\",  \n",
    "                  index = None, \n",
    "                  header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `.info()`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>account_opening_date</th>\n",
       "      <th>demog_1</th>\n",
       "      <th>demog_3</th>\n",
       "      <th>demog_5</th>\n",
       "      <th>demog_6</th>\n",
       "      <th>demog_7</th>\n",
       "      <th>demog_8</th>\n",
       "      <th>demog_9</th>\n",
       "      <th>...</th>\n",
       "      <th>others_41</th>\n",
       "      <th>txn_80</th>\n",
       "      <th>txn_81</th>\n",
       "      <th>demog_39</th>\n",
       "      <th>demog_41</th>\n",
       "      <th>others_42</th>\n",
       "      <th>others_43</th>\n",
       "      <th>others_44</th>\n",
       "      <th>others_45</th>\n",
       "      <th>demog_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>96331.000000</td>\n",
       "      <td>99994.000000</td>\n",
       "      <td>99975.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99994.0</td>\n",
       "      <td>96249.000000</td>\n",
       "      <td>87086.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>42522.000000</td>\n",
       "      <td>48535.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>2105.000000</td>\n",
       "      <td>4579.000000</td>\n",
       "      <td>874.000000</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2023-01-25 16:25:19.200000512</td>\n",
       "      <td>79.543376</td>\n",
       "      <td>101.323279</td>\n",
       "      <td>3.290163</td>\n",
       "      <td>1.017180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.191701</td>\n",
       "      <td>0.326103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>34.742439</td>\n",
       "      <td>22.679159</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.96329</td>\n",
       "      <td>87.887886</td>\n",
       "      <td>62.024896</td>\n",
       "      <td>28.808924</td>\n",
       "      <td>96.700288</td>\n",
       "      <td>0.958470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-01 00:00:00</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-26 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-01-25 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-02-24 00:00:00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023-03-31 00:00:00</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13907.000000</td>\n",
       "      <td>7810.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4049.000000</td>\n",
       "      <td>3283.000000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>0.140001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.498781</td>\n",
       "      <td>5.350011</td>\n",
       "      <td>0.833449</td>\n",
       "      <td>0.182553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641951</td>\n",
       "      <td>0.468788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>251.845838</td>\n",
       "      <td>49.903348</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.18805</td>\n",
       "      <td>298.951251</td>\n",
       "      <td>200.384998</td>\n",
       "      <td>136.963658</td>\n",
       "      <td>370.396893</td>\n",
       "      <td>0.199514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Primary key         Target           account_opening_date  \\\n",
       "count  100000.000000  100000.000000                         100000   \n",
       "mean    50000.500000       0.020000  2023-01-25 16:25:19.200000512   \n",
       "min         1.000000       0.000000            2022-12-01 00:00:00   \n",
       "25%     25000.750000       0.000000            2022-12-26 00:00:00   \n",
       "50%     50000.500000       0.000000            2023-01-25 00:00:00   \n",
       "75%     75000.250000       0.000000            2023-02-24 00:00:00   \n",
       "max    100000.000000       1.000000            2023-03-31 00:00:00   \n",
       "std     28867.657797       0.140001                            NaN   \n",
       "\n",
       "            demog_1       demog_3       demog_5       demog_6  demog_7  \\\n",
       "count  96331.000000  99994.000000  99975.000000  99999.000000  99994.0   \n",
       "mean      79.543376    101.323279      3.290163      1.017180      1.0   \n",
       "min       51.000000    101.000000      1.000000      1.000000      1.0   \n",
       "25%       55.000000    101.000000      3.000000      1.000000      1.0   \n",
       "50%       55.000000    101.000000      4.000000      1.000000      1.0   \n",
       "75%       55.000000    101.000000      4.000000      1.000000      1.0   \n",
       "max      421.000000    213.000000      4.000000      4.000000      1.0   \n",
       "std       89.498781      5.350011      0.833449      0.182553      0.0   \n",
       "\n",
       "            demog_8       demog_9  ...     others_41        txn_80  \\\n",
       "count  96249.000000  87086.000000  ...  99999.000000  42522.000000   \n",
       "mean      41.191701      0.326103  ...      0.002220     34.742439   \n",
       "min       41.000000      0.000000  ...      0.000000      1.000000   \n",
       "25%       41.000000      0.000000  ...      0.000000      2.000000   \n",
       "50%       41.000000      0.000000  ...      0.000000      5.000000   \n",
       "75%       41.000000      1.000000  ...      0.000000     15.000000   \n",
       "max       52.000000      1.000000  ...      1.000000  13907.000000   \n",
       "std        0.641951      0.468788  ...      0.047065    251.845838   \n",
       "\n",
       "             txn_81       demog_39      demog_41    others_42    others_43  \\\n",
       "count  48535.000000  100000.000000  100000.00000  2105.000000  4579.000000   \n",
       "mean      22.679159       0.999940       0.96329    87.887886    62.024896   \n",
       "min        1.000000       0.000000       0.00000     0.000000     0.000000   \n",
       "25%        6.000000       1.000000       1.00000     0.000000     0.000000   \n",
       "50%       12.000000       1.000000       1.00000     0.000000     0.000000   \n",
       "75%       27.000000       1.000000       1.00000     2.000000     4.000000   \n",
       "max     7810.000000       1.000000       1.00000  4049.000000  3283.000000   \n",
       "std       49.903348       0.007746       0.18805   298.951251   200.384998   \n",
       "\n",
       "         others_44    others_45       demog_42  \n",
       "count   874.000000   694.000000  100000.000000  \n",
       "mean     28.808924    96.700288       0.958470  \n",
       "min       0.000000     0.000000       0.000000  \n",
       "25%       0.000000     0.000000       1.000000  \n",
       "50%       0.000000     0.000000       1.000000  \n",
       "75%       0.000000     0.000000       1.000000  \n",
       "max    2922.000000  3603.000000       1.000000  \n",
       "std     136.963658   370.396893       0.199514  \n",
       "\n",
       "[8 rows x 166 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key                      int64\n",
       "Target                           int64\n",
       "account_opening_date    datetime64[ns]\n",
       "country_code                    object\n",
       "demog_1                        float64\n",
       "                             ...      \n",
       "others_43                      float64\n",
       "others_44                      float64\n",
       "others_45                      float64\n",
       "demog_42                         int64\n",
       "demog_43                        object\n",
       "Length: 178, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key             100000\n",
       "Target                       2\n",
       "account_opening_date       121\n",
       "country_code                49\n",
       "demog_1                     16\n",
       "                         ...  \n",
       "others_43                  479\n",
       "others_44                   99\n",
       "others_45                  135\n",
       "demog_42                     2\n",
       "demog_43                     3\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary key                 0\n",
       "Target                      0\n",
       "account_opening_date        0\n",
       "country_code             3666\n",
       "demog_1                  3669\n",
       "                        ...  \n",
       "others_43               95421\n",
       "others_44               99126\n",
       "others_45               99306\n",
       "demog_42                    0\n",
       "demog_43                 3705\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing the `columns` of the `train_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary key', 'Target', 'account_opening_date', 'country_code',\n",
       "       'demog_1', 'demog_2', 'income', 'demog_3', 'city_tier', 'occupation',\n",
       "       ...\n",
       "       'demog_39', 'email_domain', 'demog_40', 'demog_41', 'others_42',\n",
       "       'others_43', 'others_44', 'others_45', 'demog_42', 'demog_43'],\n",
       "      dtype='object', length=178)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the `cols` against `Target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exclude 'Primary key' column and split into batches of 40 columns each\n",
    "columns_to_plot = [col for col in train_df.columns if col != 'Primary key']\n",
    "batch_size = 40\n",
    "\n",
    "# Create a directory to save the images (change the path as needed)\n",
    "image_directory = '/mnt/c/Users/parth/Desktop/CODING/Convolve_Round2/image_directory/'\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "\n",
    "# Create plots for the first batch of attributes against 'Target' and save as images\n",
    "for i in range(0, min(batch_size, len(columns_to_plot))):\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    \n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the second batch of attributes against 'Target'\n",
    "for i in range(batch_size, 2 * batch_size):\n",
    "    if i >= len(columns_to_plot):\n",
    "        break\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the third batch of attributes against 'Target'\n",
    "for i in range(2 * batch_size, 3 * batch_size):\n",
    "    if i >= len(columns_to_plot):\n",
    "        break\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    \n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for the fourth batch of attributes against 'Target'\n",
    "for i in range(3 * batch_size, len(columns_to_plot)):\n",
    "    column = columns_to_plot[i]\n",
    "    fig = px.histogram(train_df, x=column, color='Target', title=f'{column} vs Target')\n",
    "    # Save the figure as an image\n",
    "    image_file_path = f'{image_directory}{column}_vs_Target.png'\n",
    "    pio.write_image(fig, image_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The images are saved in a file as they are heavy files and slowing down the notebook.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we infer from the graphs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `txn_61`\n",
    "  - 1871 points have target 1\n",
    "  - Value 0 -> Always\n",
    "- `txn_62`\n",
    "  - Value 0 -> 1866 have target 1\n",
    "  - Value 1 -> 696 have target 0, very few have target 1\n",
    "- `txn_63`\n",
    "  - Value 0 -> 1867 have target 1\n",
    "  - At other datapoints very less values of both targets\n",
    "- `txn_64`\n",
    "  - Value 0 -> Many mules , target value 1\n",
    "  - Mules happen at single digit values, but it takes values till 200.\n",
    "- `txn_65`\n",
    "  - Value -> Always 0\n",
    "  - 1871 have target 1\n",
    "- `txn_66`\n",
    "  - 1800s have target 1\n",
    "  - Value 0 -> Always\n",
    "- `txn_67`\n",
    "  - Target 1 at Values 0 like before\n",
    "- `txn_68`\n",
    "  - Wide range of values from 0 - 17000\n",
    "  - Value 0 -> 1800s mules\n",
    "  - Few mules , max till value till 700.\n",
    "- `txn_69`\n",
    "  - Value 0 -> 1200s\n",
    "  - Value 1 -> 500s\n",
    "  - Value 2 -> 150s\n",
    "  - Value 3 -> 70s\n",
    "  - Mules till 15.\n",
    "- `txn_70`\n",
    "  - Value only 0, 1800s target 1\n",
    "- `txn_73`\n",
    "  - Different & Visible pattern\n",
    "  - Decreasing graph\n",
    "- `txn_74`\n",
    "  - Different pattern\n",
    "  - Like txn_73\n",
    "- `txn_75`\n",
    "  - Different pattern like txn_74\n",
    "- `txn_76`\n",
    "  - Different and like txn_75\n",
    "- `txn_77`\n",
    "  - Slightly higher peak at zero, like txn_76\n",
    "  - Different pattern, slight right skewness\n",
    "- `txn_78`\n",
    "  - Like `txn_77`\n",
    "- `txn_79`\n",
    "  - Like txn_78\n",
    "\n",
    "`txn_73` :- `txn_80` ,`txn_81`(Peak spikes), \n",
    "  \n",
    "\n",
    "- `others_1`\n",
    "  - Value 0 -> 1700s Mules\n",
    "  - Value 1 -> 200s Mules\n",
    "- `others_3`\n",
    "  - Proportion of mules at Value 1 more\n",
    "- `others_6`\n",
    "  - Different pattern\n",
    "  - Number of Mules at lower values are higher in comparison to later values.\n",
    "- `others_7`\n",
    "  - Same like other_6, looks important.\n",
    "- `others_8`\n",
    "  - Mules at lower values only.\n",
    "- `others_9`\n",
    "  - Looks important, like others_6.\n",
    "- `others_10`\n",
    "  - Looks like others_6\n",
    "- `others_12`\n",
    "  - Looks like others_6\n",
    "- `others_11`\n",
    "  - Like others_8\n",
    "\n",
    "`others_6` :- `others_13` ,`others_15` , `others_16`  \n",
    "`others_8` :- `others_14` , `others_17` , `others_18` , `others_19`, `others_20` ,`others_21` ,`others_22` ,`others_24`, `others_25` ,`others_23` , `others_26` ,`others_29`,`others_30`,`others_31`,`others_32`,`others_37`\n",
    "\n",
    "\n",
    "\n",
    "- `others_36`\n",
    "  - Different pattern, mules at higher values.\n",
    "\n",
    "\n",
    "`email_domain` :No pattern as such\n",
    "\n",
    "`demog_40` , `demog_43`: Categorical , interesting, column . High value imples more mules.\n",
    "`others_42` : Mules at lower values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Target`\n",
    "Only 2% of our targets are 1, such low number of mules banks makes sense\n",
    "\n",
    "- `Dates`\n",
    "Dates have been given last 4 months of financial year 2022-23. There is slight rise in mules in later part of January\n",
    "\n",
    "- `Country Code`\n",
    "Most of the people are from India(above 90%) and all mules are Indians\n",
    "\n",
    "- `Demog_2`\n",
    "There is a significant rise in Mule values around 2 and 3 \n",
    "\n",
    "- `Income`\n",
    "There is a trend of more mules with lower income values.\n",
    "\n",
    "- `City-Tier`\n",
    "Higher number of mules from Rural area, and significantly less from Tier-1\n",
    "\n",
    "- `Occupation`\n",
    "Saliered and Student have very low percentage of mules, Self-Employed have significantly high number of mules.\n",
    "\n",
    "- `Demog_4`\n",
    "Most frauders have N value but 90% of values are itself N.\n",
    "\n",
    "- `Demog_9`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Deomog_13`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Deomog_14`\n",
    "Higher percent of values from -0.5 to 0.5\n",
    "\n",
    "- `Demog_20`\n",
    "Significant drop from 0.5 to 1.5\n",
    "\n",
    "- `Demog_21`\n",
    "Significant drop from 0.5 to 1.5\n",
    "\n",
    "- `Demog_22`\n",
    "All mules in Y, but very low number of N in total\n",
    "\n",
    "- `os`\n",
    "Significant mules in Android, only 0.8% of IoS are mules\n",
    "\n",
    "- `tx_1-15`\n",
    "Most values are 0 itself(distribution is also very similar expect very few outliers)\n",
    "\n",
    "- `tx_53`\n",
    "Still mules around 0 and 1 values but different from general pattern, mules are more on 0 than 1.\n",
    "\n",
    "- `tx_54`\n",
    "High number of values at 2 but very low mules.\n",
    "\n",
    "- `demog_23` , `demog_32`\n",
    "Lower values have higher mules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making trucated DF\n",
    "\n",
    "Based on our observation , new truncated dataframe is made with those features removed that we surely think are not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_1873/1953221906.py:9: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create empty DataFrames to store numerical and categorical columns\n",
    "truncated_df_numerical = pd.DataFrame()\n",
    "truncated_df_categorical = pd.DataFrame()\n",
    "\n",
    "# Loop through the columns in train_df and categorize them\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].dtype in ['int64', 'float64']:\n",
    "        # Numerical column\n",
    "        truncated_df_numerical[column] = train_df[column]\n",
    "    else:\n",
    "        # Categorical column\n",
    "        truncated_df_categorical[column] = train_df[column]\n",
    "\n",
    "# Now, truncated_df_numerical will contain all numerical columns,\n",
    "# and truncated_df_categorical will contain all categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>demog_1</th>\n",
       "      <th>demog_3</th>\n",
       "      <th>demog_5</th>\n",
       "      <th>demog_6</th>\n",
       "      <th>demog_7</th>\n",
       "      <th>demog_8</th>\n",
       "      <th>demog_9</th>\n",
       "      <th>demog_11</th>\n",
       "      <th>...</th>\n",
       "      <th>others_41</th>\n",
       "      <th>txn_80</th>\n",
       "      <th>txn_81</th>\n",
       "      <th>demog_39</th>\n",
       "      <th>demog_41</th>\n",
       "      <th>others_42</th>\n",
       "      <th>others_43</th>\n",
       "      <th>others_44</th>\n",
       "      <th>others_45</th>\n",
       "      <th>demog_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Primary key  Target  demog_1  demog_3  demog_5  demog_6  demog_7  demog_8  \\\n",
       "0            1       0     53.0    101.0      3.0      1.0      1.0     41.0   \n",
       "1            2       0     55.0    101.0      2.0      1.0      1.0     41.0   \n",
       "2            3       0     55.0    101.0      4.0      1.0      1.0     41.0   \n",
       "3            4       0     53.0    101.0      4.0      1.0      1.0     41.0   \n",
       "4            5       0     55.0    101.0      4.0      1.0      1.0     41.0   \n",
       "\n",
       "   demog_9  demog_11  ...  others_41  txn_80  txn_81  demog_39  demog_41  \\\n",
       "0      0.0       0.0  ...        0.0     1.0     1.0         1         1   \n",
       "1      1.0       0.0  ...        0.0    12.0    28.0         1         1   \n",
       "2      0.0       0.0  ...        0.0     5.0    48.0         1         1   \n",
       "3      NaN       0.0  ...        0.0     1.0    10.0         1         1   \n",
       "4      0.0       0.0  ...        0.0     NaN     NaN         1         1   \n",
       "\n",
       "   others_42  others_43  others_44  others_45  demog_42  \n",
       "0        NaN        0.0        NaN        NaN         1  \n",
       "1        NaN        NaN        NaN        NaN         1  \n",
       "2        NaN        NaN        NaN        NaN         1  \n",
       "3        NaN        NaN        NaN        NaN         1  \n",
       "4        NaN        NaN        NaN        NaN         1  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_df_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_opening_date</th>\n",
       "      <th>country_code</th>\n",
       "      <th>demog_2</th>\n",
       "      <th>income</th>\n",
       "      <th>city_tier</th>\n",
       "      <th>occupation</th>\n",
       "      <th>demog_4</th>\n",
       "      <th>demog_10</th>\n",
       "      <th>demog_22</th>\n",
       "      <th>os</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>demog_40</th>\n",
       "      <th>demog_43</th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>ios</td>\n",
       "      <td>gmail</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "      <td>gmail</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "      <td>gmail</td>\n",
       "      <td>medium</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "      <td>gmail</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "      <td>gmail</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_opening_date country_code demog_2        income city_tier  \\\n",
       "0           2023-02-18           IN       3  100001 to 5L     Rural   \n",
       "1           2023-02-01           IN       1       0 to 1L    Tier 1   \n",
       "2           2022-12-09           IN       3       0 to 1L    Tier 2   \n",
       "3           2023-03-31           IN       3  100001 to 5L    Tier 7   \n",
       "4           2023-01-17           IN       6       0 to 1L    Tier 1   \n",
       "\n",
       "      occupation demog_4 demog_10 demog_22   os email_domain demog_40  \\\n",
       "0  Self_Employed       N        N        Y  ios        gmail      low   \n",
       "1       Salaried       N        N        Y  and        gmail     High   \n",
       "2  Self_Employed       N        N        Y  and        gmail   medium   \n",
       "3  Self_Employed       N        N        Y  and        gmail     High   \n",
       "4        Student       N        N        Y  and        gmail      low   \n",
       "\n",
       "  demog_43  Primary key  Target  \n",
       "0   medium            1       0  \n",
       "1     High            2       0  \n",
       "2     High            3       0  \n",
       "3     High            4       0  \n",
       "4   medium            5       0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_df_categorical['Primary key'] = truncated_df_numerical['Primary key']\n",
    "truncated_df_categorical['Target'] = truncated_df_numerical['Target']\n",
    "\n",
    "\n",
    "truncated_df_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling `NaN` values with `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_df_numerical_filled = truncated_df_numerical.fillna(0)\n",
    "truncated_df_categorical_filled = truncated_df_categorical.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering only important columns based on previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary key', 'Target', 'demog_1', 'demog_3', 'demog_5', 'demog_6',\n",
       "       'demog_7', 'demog_8', 'demog_9', 'demog_11',\n",
       "       ...\n",
       "       'others_41', 'txn_80', 'txn_81', 'demog_39', 'demog_41', 'others_42',\n",
       "       'others_43', 'others_44', 'others_45', 'demog_42'],\n",
       "      dtype='object', length=165)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_df_numerical_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['account_opening_date', 'country_code', 'demog_2', 'income',\n",
       "       'city_tier', 'occupation', 'demog_4', 'demog_10', 'demog_22', 'os',\n",
       "       'email_domain', 'demog_40', 'demog_43', 'Primary key', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_df_categorical_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/3919568207.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of important column names\n",
    "important_columns = [\"Primary key\", \"Target\",\"txn_62\",\"txn_64\",\"txn_68\",\"txn_69\",\"txn_73\",\"txn_74\",\"txn_75\",\"txn_76\",\"txn_77\",\"txn_79\",\"txn_80\",\"txn_81\",\"others_1\",\"others_3\",\"others_6\",\"others_7\",\"others_8\",\"others_9\",\"others_10\",\"others_12\",\"others_11\",\"others_13\",\"others_15\",\"others_16\",\"others_14\",\"others_17\",\"others_18\",\"others_19\",\"others_20\",\"others_21\",\"others_22\",\"others_24\",\"others_25\",\"others_23\",\"others_26\",\"others_29\",\"others_30\",\"others_31\",\"others_32\",\"others_37\",\"others_36\",\"demog_40\",\"demog_43\",\"others_42\",\"Dates\",\"country_code\",\"demog_2\",\"income\",\"city_tier\",\"occupation\",\"demog_4\",\"demog_9\",\"demog_13\",\"demog_14\",\"demog_20\",\"demog_21\",\"demog_22\",\"os\",\"txn_53\",\"txn_54\",\"demog_23\",\"demog_32\"]  # Add your important columns here\n",
    "\n",
    "\n",
    "# Create new dataframes with only the important columns for numerical data\n",
    "new_df_numerical = truncated_df_numerical_filled[[\"Primary key\", \"Target\"]]  # Initialize with Primary Key and Target columns\n",
    "\n",
    "for col in important_columns[2:]:\n",
    "    if col in truncated_df_numerical_filled.columns:\n",
    "        new_df_numerical[col] = truncated_df_numerical_filled[col]\n",
    "\n",
    "# Create new dataframes with only the important columns for categorical data\n",
    "new_df_categorical = truncated_df_categorical_filled[[\"Primary key\", \"Target\"]]  # Initialize with Primary Key and Target columns\n",
    "\n",
    "for col in important_columns[2:]:\n",
    "    if col in truncated_df_categorical_filled.columns:\n",
    "        new_df_categorical[col] = truncated_df_categorical_filled[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df_numerical.columns)-2+len(new_df_categorical.columns)-2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary key', 'Target', 'txn_62', 'txn_64', 'txn_68', 'txn_69',\n",
       "       'txn_73', 'txn_74', 'txn_75', 'txn_76', 'txn_77', 'txn_79', 'txn_80',\n",
       "       'txn_81', 'others_1', 'others_3', 'others_6', 'others_7', 'others_8',\n",
       "       'others_9', 'others_10', 'others_12', 'others_11', 'others_13',\n",
       "       'others_15', 'others_16', 'others_14', 'others_17', 'others_18',\n",
       "       'others_19', 'others_20', 'others_21', 'others_22', 'others_24',\n",
       "       'others_25', 'others_23', 'others_26', 'others_29', 'others_30',\n",
       "       'others_31', 'others_32', 'others_37', 'others_36', 'others_42',\n",
       "       'demog_9', 'demog_13', 'demog_14', 'demog_20', 'demog_21', 'txn_53',\n",
       "       'txn_54', 'demog_23', 'demog_32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary key', 'Target', 'demog_40', 'demog_43', 'country_code',\n",
       "       'demog_2', 'income', 'city_tier', 'occupation', 'demog_4', 'demog_22',\n",
       "       'os'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>demog_40</th>\n",
       "      <th>demog_43</th>\n",
       "      <th>country_code</th>\n",
       "      <th>demog_2</th>\n",
       "      <th>income</th>\n",
       "      <th>city_tier</th>\n",
       "      <th>occupation</th>\n",
       "      <th>demog_4</th>\n",
       "      <th>demog_22</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99996</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99998</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Primary key  Target demog_40 demog_43 country_code demog_2  \\\n",
       "0                1       0      low   medium           IN       3   \n",
       "1                2       0     High     High           IN       1   \n",
       "2                3       0   medium     High           IN       3   \n",
       "3                4       0     High     High           IN       3   \n",
       "4                5       0      low   medium           IN       6   \n",
       "...            ...     ...      ...      ...          ...     ...   \n",
       "99995        99996       1     High     High           IN       2   \n",
       "99996        99997       1      low   medium           IN       6   \n",
       "99997        99998       1     High   medium           IN       1   \n",
       "99998        99999       1     High     High           IN       1   \n",
       "99999       100000       1   medium   medium           IN       2   \n",
       "\n",
       "             income city_tier     occupation demog_4 demog_22   os  \n",
       "0      100001 to 5L     Rural  Self_Employed       N        Y  ios  \n",
       "1           0 to 1L    Tier 1       Salaried       N        Y  and  \n",
       "2           0 to 1L    Tier 2  Self_Employed       N        Y  and  \n",
       "3      100001 to 5L    Tier 7  Self_Employed       N        Y  and  \n",
       "4           0 to 1L    Tier 1        Student       N        Y  and  \n",
       "...             ...       ...            ...     ...      ...  ...  \n",
       "99995       0 to 1L     Rural  Self_Employed       N        Y  and  \n",
       "99996  100001 to 5L     Rural        Student       N        Y  and  \n",
       "99997  100001 to 5L    Tier 6       Salaried       N        Y  and  \n",
       "99998     5L to 10L    Tier 1          Other       N        Y  ios  \n",
       "99999     5L to 10L    Tier 7  Self_Employed       N        Y  and  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_1873/1944393124.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>demog_40</th>\n",
       "      <th>demog_43</th>\n",
       "      <th>country_code</th>\n",
       "      <th>demog_2</th>\n",
       "      <th>income</th>\n",
       "      <th>city_tier</th>\n",
       "      <th>occupation</th>\n",
       "      <th>demog_4</th>\n",
       "      <th>demog_22</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99996</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>0 to 1L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99998</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Primary key  Target demog_40 demog_43 country_code demog_2  \\\n",
       "0                1       0      low   medium           IN       3   \n",
       "1                2       0     High     High           IN       1   \n",
       "2                3       0   medium     High           IN       3   \n",
       "3                4       0     High     High           IN       3   \n",
       "4                5       0      low   medium           IN       6   \n",
       "...            ...     ...      ...      ...          ...     ...   \n",
       "99995        99996       1     High     High           IN       2   \n",
       "99996        99997       1      low   medium           IN       6   \n",
       "99997        99998       1     High   medium           IN       1   \n",
       "99998        99999       1     High     High           IN       1   \n",
       "99999       100000       1   medium   medium           IN       2   \n",
       "\n",
       "             income city_tier     occupation demog_4 demog_22   os  \n",
       "0      100001 to 5L     Rural  Self_Employed       N        Y  ios  \n",
       "1           0 to 1L    Tier 1       Salaried       N        Y  and  \n",
       "2           0 to 1L    Tier 2  Self_Employed       N        Y  and  \n",
       "3      100001 to 5L    Tier 7  Self_Employed       N        Y  and  \n",
       "4           0 to 1L    Tier 1        Student       N        Y  and  \n",
       "...             ...       ...            ...     ...      ...  ...  \n",
       "99995       0 to 1L     Rural  Self_Employed       N        Y  and  \n",
       "99996  100001 to 5L     Rural        Student       N        Y  and  \n",
       "99997  100001 to 5L    Tier 6       Salaried       N        Y  and  \n",
       "99998     5L to 10L    Tier 1          Other       N        Y  ios  \n",
       "99999     5L to 10L    Tier 7  Self_Employed       N        Y  and  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"demog_40\",\"demog_43\",\"country_code\",\"demog_2\",\"income\",\"city_tier\",\"occupation\",\"demog_4\",\"demog_22\",\"os\"]\n",
    "\n",
    "for col in cols:\n",
    "    new_df_categorical[col] = new_df_categorical[col].astype(str)\n",
    "    \n",
    "new_df_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematically Exploring Modeling Strategies\n",
    "\n",
    "Scikit-learn offers the following cheatsheet to decide which model to pick.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering the properties of our `Dataset`\n",
    "\n",
    "1. SGD Classifier\n",
    "2. Kernel Approximation\n",
    "3. SGD Regressor\n",
    "4. Laso\n",
    "5. ElasticNet\n",
    "6. RidgeRegression\n",
    "7. SVR(kernel='linear')\n",
    "8. SVR(kernel='rbf')\n",
    "9. ENsembleRegressor\n",
    "10. Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993969696969697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your data into two separate DataFrames (numerical_df and categorical_df)\n",
    "\n",
    "# Assuming numerical_df and categorical_df have the same primary key and target label column names\n",
    "primary_key_col = 'Primary key'\n",
    "target_col = 'Target'\n",
    "\n",
    "# Merge the numerical and categorical DataFrames on the primary key column\n",
    "merged_df = pd.merge(new_df_categorical, new_df_numerical, on=[primary_key_col,target_col])\n",
    "\n",
    "# Split the merged data into train and test sets\n",
    "X = merged_df.drop(columns=[primary_key_col, target_col])\n",
    "y = merged_df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # You can customize this preprocessing as needed\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use one-hot encoding for categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create an SGD classifier and define your model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SGDClassifier())])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model Accuracy: 0.98\n",
      "Our model stats : 0.013969696969696965\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create a dummy model that always predicts 0 (most frequent class)\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Train the dummy model on the training data\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the dummy model\n",
    "dummy_y_pred = dummy_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the dummy model\n",
    "dummy_accuracy = accuracy_score(y_test, dummy_y_pred)\n",
    "print(f\"Dummy Model Accuracy: {dummy_accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"Our model stats : {accuracy-dummy_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on only 1's to know mule detection accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Positive Class: 0.808\n"
     ]
    }
   ],
   "source": [
    "# Create a test dataset with only rows having label 1\n",
    "test_data_positive = merged_df[merged_df['Target'] == 1].copy()\n",
    "\n",
    "# Split the test data into features (X_test_positive) and labels (y_test_positive)\n",
    "X_test_positive = test_data_positive.drop(columns=[primary_key_col])\n",
    "y_test_positive = test_data_positive['Target']  # Use the correct column name for the target variable\n",
    "\n",
    "# Make predictions using your model on the test data with label 1s\n",
    "y_pred_positive = model.predict(X_test_positive)\n",
    "\n",
    "# Calculate accuracy on the positive class predictions\n",
    "positive_accuracy = accuracy_score(y_test_positive, y_pred_positive)\n",
    "print(f\"Accuracy on Positive Class: {positive_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Formating the `test_df` for the final prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>country_code</th>\n",
       "      <th>demog_2</th>\n",
       "      <th>income</th>\n",
       "      <th>city_tier</th>\n",
       "      <th>occupation</th>\n",
       "      <th>demog_4</th>\n",
       "      <th>demog_9</th>\n",
       "      <th>demog_13</th>\n",
       "      <th>demog_14</th>\n",
       "      <th>...</th>\n",
       "      <th>others_32</th>\n",
       "      <th>demog_23</th>\n",
       "      <th>demog_32</th>\n",
       "      <th>others_36</th>\n",
       "      <th>others_37</th>\n",
       "      <th>txn_80</th>\n",
       "      <th>txn_81</th>\n",
       "      <th>demog_40</th>\n",
       "      <th>others_42</th>\n",
       "      <th>demog_43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000001</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000002</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000003</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000004</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000005</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9049996</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>9049997</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9049998</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>9049999</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9050000</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Primary key country_code demog_2        income city_tier     occupation  \\\n",
       "0         9000001           IN       2     5L to 10L    Tier 7  Self_Employed   \n",
       "1         9000002           IN       1  100001 to 5L    Tier 5       Salaried   \n",
       "2         9000003           IN       1  100001 to 5L    Tier 1          Other   \n",
       "3         9000004           IN       1  100001 to 5L    Tier 1          Other   \n",
       "4         9000005           IN       1  100001 to 5L    Tier 5          Other   \n",
       "...           ...          ...     ...           ...       ...            ...   \n",
       "49995     9049996           IN       2  100001 to 5L    Tier 6  Self_Employed   \n",
       "49996     9049997           IN       3  100001 to 5L    Tier 2  Self_Employed   \n",
       "49997     9049998           IN       3     5L to 10L     Rural  Self_Employed   \n",
       "49998     9049999           IN       6  100001 to 5L    Tier 5        Student   \n",
       "49999     9050000           IN       3  100001 to 5L    Tier 6  Self_Employed   \n",
       "\n",
       "      demog_4  demog_9  demog_13  demog_14  ...  others_32  demog_23 demog_32  \\\n",
       "0           N      1.0       1.0       0.0  ...        0.0     133.0      1.0   \n",
       "1           N      0.0       1.0       0.0  ...        0.0     202.0      0.0   \n",
       "2           N      0.0       1.0       0.0  ...        0.0     211.0      0.0   \n",
       "3           N      0.0       1.0       0.0  ...        0.0     243.0      0.0   \n",
       "4           N      0.0       1.0       0.0  ...        0.0     190.0      1.0   \n",
       "...       ...      ...       ...       ...  ...        ...       ...      ...   \n",
       "49995       N      0.0       0.0       0.0  ...        0.0     116.0      0.0   \n",
       "49996       N      0.0       1.0       0.0  ...        0.0      59.0      0.0   \n",
       "49997       N      0.0       1.0       0.0  ...        0.0     104.0      0.0   \n",
       "49998       N      0.0       1.0       0.0  ...        0.0      50.0      1.0   \n",
       "49999       N      0.0       1.0       0.0  ...        0.0      10.0      0.0   \n",
       "\n",
       "      others_36  others_37  txn_80  txn_81  demog_40  others_42  demog_43  \n",
       "0           1.0        0.0     6.0     9.0      High        0.0      High  \n",
       "1           0.0        0.0     0.0     0.0       low        0.0    medium  \n",
       "2           0.0        0.0    14.0    25.0       low        0.0    medium  \n",
       "3           1.0        0.0     2.0    21.0    medium        0.0      High  \n",
       "4           0.0        0.0     0.0     0.0       low        0.0      High  \n",
       "...         ...        ...     ...     ...       ...        ...       ...  \n",
       "49995       1.0        0.0    24.0     2.0      High        0.0      High  \n",
       "49996       0.0        0.0    11.0    20.0      High        0.0      High  \n",
       "49997       1.0        0.0    28.0    18.0       low        0.0      High  \n",
       "49998       1.0        0.0  2874.0     7.0      High        0.0    medium  \n",
       "49999       0.0        0.0     6.0     9.0      High        0.0      High  \n",
       "\n",
       "[50000 rows x 62 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of important column names\n",
    "important_columns = [\"Primary key\", \"Target\",\"txn_62\",\"txn_64\",\"txn_68\",\"txn_69\",\"txn_73\",\"txn_74\",\"txn_75\",\"txn_76\",\"txn_77\",\"txn_79\",\"txn_80\",\"txn_81\",\"others_1\",\"others_3\",\"others_6\",\"others_7\",\"others_8\",\"others_9\",\"others_10\",\"others_12\",\"others_11\",\"others_13\",\"others_15\",\"others_16\",\"others_14\",\"others_17\",\"others_18\",\"others_19\",\"others_20\",\"others_21\",\"others_22\",\"others_24\",\"others_25\",\"others_23\",\"others_26\",\"others_29\",\"others_30\",\"others_31\",\"others_32\",\"others_37\",\"others_36\",\"demog_40\",\"demog_43\",\"others_42\",\"Dates\",\"country_code\",\"demog_2\",\"income\",\"city_tier\",\"occupation\",\"demog_4\",\"demog_9\",\"demog_13\",\"demog_14\",\"demog_20\",\"demog_21\",\"demog_22\",\"os\",\"txn_53\",\"txn_54\",\"demog_23\",\"demog_32\"]  # Add your important columns here\n",
    "\n",
    "total_cols = test_df.columns.to_list()\n",
    "\n",
    "for col in total_cols :\n",
    "    if(col not in important_columns):\n",
    "        test_df = test_df.drop(columns=[col])\n",
    "        \n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = new_df_categorical.columns\n",
    "num_cols = new_df_numerical.columns\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if(col in cat_cols):\n",
    "        test_df[col]=test_df[col].astype(str)\n",
    "        \n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mules predicted : 942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>country_code</th>\n",
       "      <th>demog_2</th>\n",
       "      <th>income</th>\n",
       "      <th>city_tier</th>\n",
       "      <th>occupation</th>\n",
       "      <th>demog_4</th>\n",
       "      <th>demog_9</th>\n",
       "      <th>demog_13</th>\n",
       "      <th>demog_14</th>\n",
       "      <th>...</th>\n",
       "      <th>demog_23</th>\n",
       "      <th>demog_32</th>\n",
       "      <th>others_36</th>\n",
       "      <th>others_37</th>\n",
       "      <th>txn_80</th>\n",
       "      <th>txn_81</th>\n",
       "      <th>demog_40</th>\n",
       "      <th>others_42</th>\n",
       "      <th>demog_43</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000001</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Tier 7</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000002</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000003</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000004</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000005</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9049996</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>9049997</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9049998</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>5L to 10L</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>9049999</td>\n",
       "      <td>IN</td>\n",
       "      <td>6</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 5</td>\n",
       "      <td>Student</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9050000</td>\n",
       "      <td>IN</td>\n",
       "      <td>3</td>\n",
       "      <td>100001 to 5L</td>\n",
       "      <td>Tier 6</td>\n",
       "      <td>Self_Employed</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Primary key country_code demog_2        income city_tier     occupation  \\\n",
       "0         9000001           IN       2     5L to 10L    Tier 7  Self_Employed   \n",
       "1         9000002           IN       1  100001 to 5L    Tier 5       Salaried   \n",
       "2         9000003           IN       1  100001 to 5L    Tier 1          Other   \n",
       "3         9000004           IN       1  100001 to 5L    Tier 1          Other   \n",
       "4         9000005           IN       1  100001 to 5L    Tier 5          Other   \n",
       "...           ...          ...     ...           ...       ...            ...   \n",
       "49995     9049996           IN       2  100001 to 5L    Tier 6  Self_Employed   \n",
       "49996     9049997           IN       3  100001 to 5L    Tier 2  Self_Employed   \n",
       "49997     9049998           IN       3     5L to 10L     Rural  Self_Employed   \n",
       "49998     9049999           IN       6  100001 to 5L    Tier 5        Student   \n",
       "49999     9050000           IN       3  100001 to 5L    Tier 6  Self_Employed   \n",
       "\n",
       "      demog_4  demog_9  demog_13  demog_14  ...  demog_23  demog_32 others_36  \\\n",
       "0           N      1.0       1.0       0.0  ...     133.0       1.0       1.0   \n",
       "1           N      0.0       1.0       0.0  ...     202.0       0.0       0.0   \n",
       "2           N      0.0       1.0       0.0  ...     211.0       0.0       0.0   \n",
       "3           N      0.0       1.0       0.0  ...     243.0       0.0       1.0   \n",
       "4           N      0.0       1.0       0.0  ...     190.0       1.0       0.0   \n",
       "...       ...      ...       ...       ...  ...       ...       ...       ...   \n",
       "49995       N      0.0       0.0       0.0  ...     116.0       0.0       1.0   \n",
       "49996       N      0.0       1.0       0.0  ...      59.0       0.0       0.0   \n",
       "49997       N      0.0       1.0       0.0  ...     104.0       0.0       1.0   \n",
       "49998       N      0.0       1.0       0.0  ...      50.0       1.0       1.0   \n",
       "49999       N      0.0       1.0       0.0  ...      10.0       0.0       0.0   \n",
       "\n",
       "      others_37  txn_80  txn_81  demog_40  others_42  demog_43  Target  \n",
       "0           0.0     6.0     9.0      High        0.0      High       0  \n",
       "1           0.0     0.0     0.0       low        0.0    medium       0  \n",
       "2           0.0    14.0    25.0       low        0.0    medium       0  \n",
       "3           0.0     2.0    21.0    medium        0.0      High       0  \n",
       "4           0.0     0.0     0.0       low        0.0      High       0  \n",
       "...         ...     ...     ...       ...        ...       ...     ...  \n",
       "49995       0.0    24.0     2.0      High        0.0      High       0  \n",
       "49996       0.0    11.0    20.0      High        0.0      High       1  \n",
       "49997       0.0    28.0    18.0       low        0.0      High       0  \n",
       "49998       0.0  2874.0     7.0      High        0.0    medium       1  \n",
       "49999       0.0     6.0     9.0      High        0.0      High       1  \n",
       "\n",
       "[50000 rows x 63 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have loaded your test data into test_df and it has the same structure as your training data without the 'Target' column.\n",
    "\n",
    "# Use your trained model to predict target values for test data\n",
    "predicted_targets = model.predict(test_df.drop(columns=['Primary key']))\n",
    "\n",
    "# Create a new column in the test_df to store the predicted target values\n",
    "test_df['Target'] = predicted_targets\n",
    "\n",
    "# Now, your test_df will have a new column 'Predicted_Target' with the predicted values\n",
    "# You can save the test_df to a CSV file or use it for further analysis as needed\n",
    "\n",
    "print(\"Number of mules predicted :\",test_df['Target'].sum())\n",
    "\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demog_40', 'demog_43', 'country_code', 'demog_2', 'income', 'city_tier', 'occupation', 'demog_4', 'demog_22', 'os']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary key</th>\n",
       "      <th>Target</th>\n",
       "      <th>txn_62</th>\n",
       "      <th>txn_64</th>\n",
       "      <th>txn_68</th>\n",
       "      <th>txn_69</th>\n",
       "      <th>txn_73</th>\n",
       "      <th>txn_74</th>\n",
       "      <th>txn_75</th>\n",
       "      <th>txn_76</th>\n",
       "      <th>...</th>\n",
       "      <th>demog_4_5</th>\n",
       "      <th>demog_4_6</th>\n",
       "      <th>demog_4_7</th>\n",
       "      <th>demog_4_N</th>\n",
       "      <th>demog_22_0</th>\n",
       "      <th>demog_22_N</th>\n",
       "      <th>demog_22_Y</th>\n",
       "      <th>os_0</th>\n",
       "      <th>os_and</th>\n",
       "      <th>os_ios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Primary key  Target  txn_62  txn_64  txn_68  txn_69  txn_73  txn_74  \\\n",
       "0                1       0     0.0     0.0     0.0     6.0     1.0     2.0   \n",
       "1                2       0     0.0     0.0     5.0     6.0    21.0   150.0   \n",
       "2                3       0     0.0     0.0     0.0     8.0    97.0   244.0   \n",
       "3                4       0     0.0     0.0     1.0     0.0     1.0     3.0   \n",
       "4                5       0     0.0     0.0     0.0     6.0     0.0     0.0   \n",
       "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "99995        99996       1     0.0     0.0     0.0     1.0     7.0     7.0   \n",
       "99996        99997       1     0.0     0.0     0.0     0.0    45.0    45.0   \n",
       "99997        99998       1     0.0     0.0     0.0     0.0    16.0    16.0   \n",
       "99998        99999       1     0.0     0.0     0.0     3.0    45.0   134.0   \n",
       "99999       100000       1     0.0     0.0     0.0     1.0    11.0   317.0   \n",
       "\n",
       "       txn_75  txn_76  ...  demog_4_5  demog_4_6  demog_4_7  demog_4_N  \\\n",
       "0         8.0    11.0  ...      False      False      False       True   \n",
       "1         6.0    20.0  ...      False      False      False       True   \n",
       "2         7.0    15.0  ...      False      False      False       True   \n",
       "3         1.0     2.0  ...      False      False      False       True   \n",
       "4         1.0     3.0  ...      False      False      False       True   \n",
       "...       ...     ...  ...        ...        ...        ...        ...   \n",
       "99995    18.0    18.0  ...      False      False      False       True   \n",
       "99996  1134.0  1134.0  ...      False      False      False       True   \n",
       "99997    19.0    19.0  ...      False      False      False       True   \n",
       "99998     7.0    20.0  ...      False      False      False       True   \n",
       "99999     6.0   121.0  ...      False      False      False       True   \n",
       "\n",
       "       demog_22_0  demog_22_N  demog_22_Y   os_0  os_and  os_ios  \n",
       "0           False       False        True  False   False    True  \n",
       "1           False       False        True  False    True   False  \n",
       "2           False       False        True  False    True   False  \n",
       "3           False       False        True  False    True   False  \n",
       "4           False       False        True  False    True   False  \n",
       "...           ...         ...         ...    ...     ...     ...  \n",
       "99995       False       False        True  False    True   False  \n",
       "99996       False       False        True  False    True   False  \n",
       "99997       False       False        True  False    True   False  \n",
       "99998       False       False        True  False   False    True  \n",
       "99999       False       False        True  False    True   False  \n",
       "\n",
       "[100000 rows x 171 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [ 'demog_40', 'demog_43', 'country_code', 'demog_2', 'income', 'city_tier', 'occupation', 'demog_4', 'demog_22', 'os']\n",
    "print(categorical_columns)\n",
    "\n",
    "# Perform one-hot encoding for the categorical columns\n",
    "one_hot_encoded = pd.get_dummies(merged_df[categorical_columns], prefix=categorical_columns)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original numerical columns\n",
    "merged_df_encoded = pd.concat([merged_df.drop(columns=categorical_columns), one_hot_encoded], axis=1)\n",
    "merged_df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SVC CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9944242424242424\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming merged_df contains both numerical and categorical features and 'Target' column\n",
    "X = merged_df.drop(columns=[primary_key_col, target_col])\n",
    "y = merged_df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # You can customize this preprocessing as needed\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use one-hot encoding for categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a LinearSVC classifier and define your model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LinearSVC(dual=True, max_iter=1000000))])  # Set dual=True and max_iter\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Positive Class: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Create a test dataset with only rows having label 1\n",
    "test_data_positive = merged_df[merged_df['Target'] == 1].copy()\n",
    "\n",
    "# Split the test data into features (X_test_positive) and labels (y_test_positive)\n",
    "X_test_positive = test_data_positive.drop(columns=[primary_key_col])\n",
    "y_test_positive = test_data_positive['Target']  # Use the correct column name for the target variable\n",
    "\n",
    "# Make predictions using your model on the test data with label 1s\n",
    "y_pred_positive = model.predict(X_test_positive)\n",
    "\n",
    "# Calculate accuracy on the positive class predictions\n",
    "positive_accuracy = accuracy_score(y_test_positive, y_pred_positive)\n",
    "print(f\"Accuracy on Positive Class: {positive_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "ch = len(y_pred)\n",
    "for i in range(ch):\n",
    "    if(y_pred[i] != y_train.to_list()[i] and y_train.to_list()[i] == 0):\n",
    "        count+=1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941515151515151\n",
      "Number of False Positives: 70\n",
      "Number of False Negatives: 123\n",
      "Number of True Nega: 32270\n",
      "Number of 69 position: 537\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming merged_df contains both numerical and categorical features and 'Target' column\n",
    "X = merged_df.drop(columns=[primary_key_col, target_col])\n",
    "y = merged_df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # You can customize this preprocessing as needed\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use one-hot encoding for categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a KNeighborsClassifier and define your model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', KNeighborsClassifier(n_neighbors=5))])  # You can customize the number of neighbors\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract the number of false positives (FP)\n",
    "false_positives = conf_matrix[0, 1]\n",
    "false_negatives = conf_matrix[1, 0]\n",
    "print(f\"Number of False Positives: {false_positives}\")\n",
    "print(f\"Number of False Negatives: {false_negatives}\")\n",
    "print(f\"Number of True Nega: {conf_matrix[0,0]}\")\n",
    "print(f\"Number of 69 position: {conf_matrix[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9943636363636363\n",
      "True Negatives: 32293\n",
      "False Positives: 47\n",
      "False Negatives: 139\n",
      "True Positives: 521\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming merged_df contains both numerical and categorical features and 'Target' column\n",
    "X = merged_df.drop(columns=[primary_key_col, target_col])\n",
    "y = merged_df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # You can customize this preprocessing as needed\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use one-hot encoding for categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create an SVC classifier with a non-linear kernel (e.g., RBF kernel)\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SVC(kernel='rbf'))])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Positives: {true_positives}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9961212121212121\n",
      "True Negatives: 32290\n",
      "False Positives: 50\n",
      "False Negatives: 78\n",
      "True Positives: 582\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming merged_df contains both numerical and categorical features and 'Target' column\n",
    "X = merged_df.drop(columns=[primary_key_col, target_col])\n",
    "y = merged_df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # You can customize this preprocessing as needed\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Use one-hot encoding for categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "print(f\"True Negatives: {true_negatives}\")\n",
    "print(f\"False Positives: {false_positives}\")\n",
    "print(f\"False Negatives: {false_negatives}\")\n",
    "print(f\"True Positives: {true_positives}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
